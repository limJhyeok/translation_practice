{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_practice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rG5o2zf9jTY"
      },
      "outputs": [],
      "source": [
        "pair = ['I want to go home', '나는 집에 가고 싶다.']\n",
        "src_sentence = pair[0]\n",
        "trg_sentence = pair[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Lang():\n",
        "  def __init__(self):\n",
        "    self.word2ix = {'<pad>': 0,\n",
        "                    '<sos>': 1, \n",
        "                    '<eos>': 2,\n",
        "                    }\n",
        "    self.ix2word = {0: '<pad>',\n",
        "                    1: '<sos>',\n",
        "                    2: '<eos>'}\n",
        "\n",
        "    self.n_words = 3\n",
        "    self.word2count = {}\n",
        "  def fromSentence(self, sentence):\n",
        "    words = [word for word in sentence.split() ]\n",
        "    for word in words:\n",
        "      if word in self.word2ix:\n",
        "        self.word2count[word] += 1\n",
        "      else:\n",
        "        self.word2ix[word] = self.n_words\n",
        "        self.ix2word[self.n_words] = word\n",
        "        self.n_words += 1\n",
        "        self.word2count[word] = 1"
      ],
      "metadata": {
        "id": "ZphHkQDP9tuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src = Lang()\n",
        "src.fromSentence(src_sentence)\n",
        "src_size = src.n_words"
      ],
      "metadata": {
        "id": "TwQelqNTCfAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self,\n",
        "               seq_length,\n",
        "               emb_dim,\n",
        "               hid_dim,\n",
        "               drop_p):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(seq_length, emb_dim)\n",
        "    self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
        "    self.dropout = nn.Dropout(drop_p)\n",
        "    \n",
        "  def forward(self, src):\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "    outputs, (hidden, cell) = self.rnn(embedded)\n",
        "\n",
        "    return outputs, (hidden, cell)"
      ],
      "metadata": {
        "id": "PJ8QOOukC2JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_words = src_sentence.split()\n",
        "n_words = len(src_words)\n",
        "MAX_SEQ_LENGTH = 10\n",
        "if n_words > MAX_SEQ_LENGTH - 2: # for <sos>, <eos> token\n",
        "  src_words = src_words[:MAX_SEQ_LENGTH-2]\n",
        "\n",
        "batch_size = 1\n",
        "src_batch = torch.zeros((MAX_SEQ_LENGTH, batch_size), dtype = torch.int64)\n",
        "for i, word in enumerate(src_words):\n",
        "  src_batch[i+1]= src.word2ix[word]\n",
        "\n",
        "src_batch[0] = src.word2ix['<sos>']\n",
        "src_batch[i+2] = src.word2ix['<eos>']"
      ],
      "metadata": {
        "id": "Z09yDPNSDlcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trg = Lang()\n",
        "trg.fromSentence(trg_sentence)\n",
        "n_token = trg.n_words"
      ],
      "metadata": {
        "id": "PYMbmE_BGCum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, seq_size, n_token, emb_dim, hid_dim, drop_p = 0.75):\n",
        "    super().__init__()\n",
        "    self.seq_size = seq_size\n",
        "    self.n_token = n_token\n",
        "    self.embedding = nn.Embedding(seq_size, emb_dim)\n",
        "    self.rnn = nn.LSTM(emb_dim, hid_dim)\n",
        "    self.dropout = nn.Dropout(drop_p)\n",
        "    self.fc = nn.Linear(hid_dim, n_token)\n",
        "\n",
        "  def forward(self, trg, hidden, cell):\n",
        "    trg = trg.unsqueeze(0) # [batch_size] -> [1, batch_size]\n",
        "    embedded = self.dropout(self.embedding(trg))\n",
        "    output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "    logits = self.fc(output)\n",
        "\n",
        "    return logits, (hidden, cell)\n"
      ],
      "metadata": {
        "id": "iEXE_HJnFQQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trg_words = trg_sentence.split()\n",
        "n_words = len(trg_words)\n",
        "MAX_SEQ_LENGTH = 10\n",
        "if n_words > MAX_SEQ_LENGTH - 2: # for <sos>, <eos> token\n",
        "  trg_words = trg_words[:MAX_SEQ_LENGTH-2]\n",
        "\n",
        "batch_size = 1\n",
        "trg_batch = torch.zeros((MAX_SEQ_LENGTH, batch_size), dtype = torch.int64)\n",
        "for i, word in enumerate(trg_words):\n",
        "  trg_batch[i+1]= trg.word2ix[word]\n",
        "trg_batch[0] = trg.word2ix['<sos>']\n",
        "trg_batch[i+2] = trg.word2ix['<eos>']"
      ],
      "metadata": {
        "id": "NEiouBKNIivv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.seq_size = decoder.seq_size\n",
        "    self.n_token = decoder.n_token\n",
        "\n",
        "  def forward(self, src, trg):\n",
        "    _, (hidden, cell) = encoder(src)\n",
        "    input = trg[0, :]\n",
        "    batch_size = 1\n",
        "    outputs = torch.zeros((self.seq_size, batch_size, self.n_token))\n",
        "    for i in range(1, self.seq_size):\n",
        "      logit, (hidden, cell) = self.decoder(input, hidden, cell)\n",
        "      outputs[i] = logit.squeeze(0)\n",
        "      \n",
        "    return outputs"
      ],
      "metadata": {
        "id": "1g5yaJ1EG3pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(MAX_SEQ_LENGTH, emb_dim = 20, hid_dim = 40, drop_p = 0.75)\n",
        "decoder = Decoder(MAX_SEQ_LENGTH, n_token, emb_dim = 20, hid_dim = 40)\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "outputs = model(src_batch, trg_batch)"
      ],
      "metadata": {
        "id": "yWznho6_PD4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = [(src_batch, trg_batch)]\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index = 0)\n",
        "learning_rate =0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "k1lIK_nm8SOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, batch, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for i, (src, trg) in enumerate(batch):\n",
        "    outputs = model(src, trg) # output: [seq_length, batch_size,  n_token] # trg: [seq_length, batch_size]\n",
        "    out_dim = outputs.size(-1)\n",
        "    outputs = outputs[1:].view(-1, out_dim)\n",
        "    trg = trg[1:].view(-1)\n",
        "    optimizer.zero_grad()    \n",
        "    loss = loss_fn(outputs, trg)\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return running_loss, model"
      ],
      "metadata": {
        "id": "Cu2s_XCSPGrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, batch, loss_fn):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  with torch.no_grad():\n",
        "    for i, (src, trg) in enumerate(batch):\n",
        "      outputs = model(src, trg)\n",
        "      out_dim = outputs.size(-1)\n",
        "      outputs = outputs[1:].view(-1, out_dim)\n",
        "      trg = trg[1:].view(-1)\n",
        "      loss = loss_fn(outputs, trg)\n",
        "      running_loss += loss.item()\n",
        "\n",
        "  return running_loss, model"
      ],
      "metadata": {
        "id": "hvZDdLATD9f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(model, batch, loss_fn, optimizer, num_epochs = 5, print_every = 100):\n",
        "  best_model = None\n",
        "  min_loss = float(\"inf\")\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss, model = train(model, batch, loss_fn, optimizer)\n",
        "    val_loss, model = evaluate(model, batch, loss_fn)\n",
        "    if (epoch+1) % print_every == 0 or epoch == 0:\n",
        "      print(f'Epoch| {epoch+1}/{num_epochs}')\n",
        "      print(f'train loss: {train_loss}')\n",
        "      print(f'val loss: {val_loss}')  \n",
        "    if min_loss > val_loss:\n",
        "      min_loss = val_loss\n",
        "      best_model = model\n",
        "\n",
        "  return best_model"
      ],
      "metadata": {
        "id": "fG9EA4KDGbEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = run(model, batch, loss_fn, optimizer, num_epochs = 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx_7lCu7HYsb",
        "outputId": "5ec258f9-75b8-44c5-f558-b44ca4ee7901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch| 1/500\n",
            "train loss: 0.0016592040192335844\n",
            "val loss: 0.0015384580474346876\n",
            "Epoch| 100/500\n",
            "train loss: 0.001490377588197589\n",
            "val loss: 0.0013969524297863245\n",
            "Epoch| 200/500\n",
            "train loss: 0.0014575652312487364\n",
            "val loss: 0.0012718020007014275\n",
            "Epoch| 300/500\n",
            "train loss: 0.0012493958929553628\n",
            "val loss: 0.0011633248068392277\n",
            "Epoch| 400/500\n",
            "train loss: 0.001154080149717629\n",
            "val loss: 0.0010671226773411036\n",
            "Epoch| 500/500\n",
            "train loss: 0.0010473668808117509\n",
            "val loss: 0.0009749621385708451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference =[]\n",
        "with torch.no_grad():\n",
        "  best_model.eval()\n",
        "  outputs = best_model(src_batch, torch.zeros((MAX_SEQ_LENGTH, batch_size), dtype = torch.long))\n",
        "  preds = outputs.argmax(-1)\n",
        "  preds = preds.squeeze(0)\n",
        "  for pred in preds:\n",
        "    inference.append(trg.ix2word[pred.item()])"
      ],
      "metadata": {
        "id": "RF66gCnjHlju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-kHeM1iLgI0",
        "outputId": "920c7328-5e84-4bcf-d513-51e2b0a8be0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad>', '나는', '집에', '가고', '싶다.', '<eos>', '<eos>', '<eos>', '<eos>', '<eos>']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    }
  ]
}